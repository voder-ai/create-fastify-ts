# 008.0-DEVELOPER-LOGS-MONITOR: Monitor with Structured Logs

## Release Goal

**Production-Ready Foundation** - Enable developers to get from zero to working API server in under 30 seconds with a single npm init command.

This story validates the template's observability and production readiness through structured logging. After the development server starts (003.0), developers need to verify that logging is working, understand the structured log output, and know how to use logs effectively for debugging in development and monitoring in production.

## How This Story Contributes

This story provides confidence that the template delivers production-grade observability and educates developers about structured logging. It enables:

- **Observability Validation**: Confirms that Pino structured logging is properly configured with sensible defaults
- **Developer Education**: Developer understands structured logging, log levels, and how to add custom context
- **Production Readiness**: Template produces machine-readable logs suitable for log aggregation tools (CloudWatch, Datadog, ELK)
- **Debugging Capability**: Developer knows how to use logs for debugging in development and troubleshooting in production
- **Integration Knowledge**: Developer understands how to integrate with production monitoring systems

## User Story

**Format**: So that I can effectively debug during development and monitor in production, as an API Developer, I want to verify that structured logs are working and understand how to use logging effectively across different environments.

**INVEST Criteria Compliance**:

- **Independent**: Depends only on 003.0 (running dev server); can be verified in parallel with other verification stories
- **Negotiable**: Specific log examples and documentation depth can be refined based on operational needs
- **Valuable**: Enables confident debugging and production monitoring - developer has observability into application behavior
- **Estimable**: Clear scope - verify logs working, understand log levels, know how to add context
- **Small**: Single iteration - focused on verification and understanding of existing logging configuration
- **Testable**: Clear success criteria - logs visible in console, developer can explain log levels and add custom logs

## Acceptance Criteria

- [ ] **Structured Logs Visible**: Running `npm run dev` shows structured JSON logs in human-readable format (via pino-pretty)
- [ ] **Request Logging Automatic**: Each HTTP request automatically logs with method, URL, status code, and response time
- [ ] **Log Levels Understood**: Developer understands when to use trace, debug, info, warn, error, and fatal log levels
- [ ] **Custom Logging Examples**: Documentation shows how to add custom log messages in route handlers
- [ ] **Request Context Logging**: Examples show how to add request-specific context using child loggers (`request.log`)
- [ ] **Production Log Format**: Documentation explains production JSON log format and shows example output
- [ ] **Log Aggregation Integration**: Guide explains how to integrate with CloudWatch, Datadog, ELK, or other log aggregation tools
- [ ] **Development vs Production**: Developer understands difference between development logs (pretty) and production logs (JSON)
- [ ] **Error Stack Traces**: Error logs include full stack traces for debugging
- [ ] **Log Level Configuration**: Documentation shows how to change log level via environment variable

## Requirements

- **REQ-LOG-STRUCTURED-JSON**: Logs output in structured JSON format suitable for machine parsing and aggregation
- **REQ-LOG-PINO-INTEGRATED**: Pino logger integrated with Fastify (per ADR 0007) with zero additional configuration
- **REQ-LOG-AUTO-REQUEST**: HTTP requests/responses automatically logged with method, URL, status, response time
- **REQ-LOG-REQUEST-CONTEXT**: Logger available on `request.log` for request-specific context
- **REQ-LOG-LEVELS-SUPPORT**: Support for all standard log levels (trace, debug, info, warn, error, fatal)
- **REQ-LOG-DEV-PRETTY**: Development logs formatted with pino-pretty for human readability
- **REQ-LOG-PROD-JSON**: Production logs output as raw JSON for log aggregation tools
- **REQ-LOG-ERROR-STACKS**: Error logs include full stack traces for debugging
- **REQ-LOG-LEVEL-CONFIG**: Log level configurable via environment variable (e.g., LOG_LEVEL=debug)
- **REQ-LOG-CUSTOM-DOCS**: Documentation with examples of adding custom log messages and context
- **REQ-LOG-AGGREGATION-GUIDE**: Guide for integrating with popular log aggregation tools

## Dependencies

- **003.0-DEVELOPER-DEV-SERVER**: Requires running server to observe log output in console

## Implementation Notes

**Logging Context**:

- Template uses Pino (per ADR 0007) which is Fastify's built-in logger with zero-config integration
- Pino is extremely fast (5x faster than Winston) with minimal performance overhead
- Structured JSON logs are perfect for production log aggregation and searching
- pino-pretty transforms JSON to human-readable format during development

**Automatic Request Logging**:

Fastify automatically logs every HTTP request/response with:

- Request method and URL
- Response status code
- Response time in milliseconds
- Request ID for correlation
- User agent and remote address (if configured)

**Log Levels Explained**:

1. **trace**: Very detailed debugging (e.g., function entry/exit, variable values)
2. **debug**: Detailed debugging information (e.g., database queries, cache hits/misses)
3. **info**: General informational messages (e.g., server started, configuration loaded) - DEFAULT
4. **warn**: Warning messages that don't prevent operation (e.g., deprecated API usage, retry attempts)
5. **error**: Error conditions that should be investigated (e.g., failed requests, caught exceptions)
6. **fatal**: Fatal errors that require immediate attention (e.g., unable to start server)

**When to Use Each Level**:

- **Production default**: info (shows important events without excessive detail)
- **Development debugging**: debug (shows detailed application behavior)
- **Troubleshooting production**: debug or trace (temporarily enabled to diagnose specific issues)
- **Always log**: error and fatal (critical for production monitoring and alerting)

**Request Context with Child Loggers**:

Child loggers automatically include request-specific context (request ID, user ID, etc.) in every log message within that request:

```javascript
// In route handler - logs automatically include request ID
request.log.info('Processing user order');
request.log.error({ orderId: 123 }, 'Order processing failed');
```

**Development vs Production Logs**:

| Aspect            | Development (pino-pretty)              | Production (JSON)                                       |
| ----------------- | -------------------------------------- | ------------------------------------------------------- |
| **Format**        | Human-readable, colorized              | Raw JSON, one line per log                              |
| **Use Case**      | Interactive debugging, console reading | Machine parsing, log aggregation                        |
| **Performance**   | Slower (formatting overhead)           | Fastest (no formatting)                                 |
| **Searchability** | Visual scanning                        | Structured queries (Elasticsearch, CloudWatch Insights) |
| **Tools**         | Terminal, VS Code console              | CloudWatch, Datadog, ELK, Splunk                        |
| **Configuration** | Enabled when NODE_ENV != production    | Automatic in production                                 |

**Example Log Output**:

Development (pino-pretty):

```
[14:23:45.123] INFO (server/12345): Server listening at http://localhost:3000
[14:23:47.456] INFO (request/67890): incoming request
    method: "GET"
    url: "/health"
[14:23:47.458] INFO (request/67890): request completed
    statusCode: 200
    responseTime: 2
```

Production (JSON):

```json
{"level":30,"time":1702307025123,"pid":12345,"hostname":"api-server","msg":"Server listening at http://localhost:3000"}
{"level":30,"time":1702307027456,"pid":12345,"hostname":"api-server","reqId":"req-67890","req":{"method":"GET","url":"/health"},"msg":"incoming request"}
{"level":30,"time":1702307027458,"pid":12345,"hostname":"api-server","reqId":"req-67890","res":{"statusCode":200},"responseTime":2,"msg":"request completed"}
```

**Log Aggregation Integration**:

Popular tools that work with Pino JSON logs:

- **AWS CloudWatch**: Use CloudWatch agent to collect logs, query with CloudWatch Insights
- **Datadog**: Forward logs via Datadog agent, search with Datadog Log Management
- **ELK Stack**: Use Filebeat/Logstash to ingest logs, search with Elasticsearch/Kibana
- **Splunk**: Use Splunk Universal Forwarder, search with Splunk queries
- **Grafana Loki**: Lightweight alternative to ELK, integrates with Grafana dashboards

All these tools can parse Pino's JSON format and enable structured queries like:

- "Show all error logs from the last hour"
- "Find requests that took longer than 1 second"
- "Group errors by endpoint and count occurrences"

**Custom Logging Examples**:

```typescript
// Basic info logging
fastify.log.info('Configuration loaded successfully');

// Logging with context
fastify.log.info({ userId: 123, action: 'login' }, 'User logged in');

// Warning with context
request.log.warn({ itemId: 456 }, 'Item not found in cache, fetching from DB');

// Error with error object (includes stack trace)
try {
  await riskyOperation();
} catch (error) {
  request.log.error({ error }, 'Operation failed');
}
```

**Environment-Based Configuration**:

```bash
# Development - debug level with pretty printing
NODE_ENV=development LOG_LEVEL=debug npm run dev

# Production - info level with JSON output
NODE_ENV=production LOG_LEVEL=info npm start

# Troubleshooting - trace level (temporary)
LOG_LEVEL=trace npm start
```

**Developer Education Goals**:

- Developer understands structured logging and why it matters for production
- Developer knows when to use each log level (not just using console.log)
- Developer knows how to add meaningful context to logs
- Developer understands development vs production log formats
- Developer knows how to integrate with production monitoring tools

**Cross-Persona Value**:

- **API Developer**: Can debug issues quickly with clear, contextual logs
- **DevOps Engineer**: Gets machine-readable logs for monitoring and alerting
- **Project Lead**: Confident that template provides production-grade observability

## Definition of Done

- [ ] Structured logs visible when running `npm run dev`
- [ ] All acceptance criteria met
- [ ] Documentation explains log levels and when to use them
- [ ] Examples show how to add custom logs with context
- [ ] Guide for production log aggregation integration
- [ ] Developer can answer "How do I debug with logs?" and "How do logs work in production?"

---

## Story Metadata

- **Story Number**: 008.0
- **Persona**: Developer (API Developer), with value for DevOps Engineer and Project Lead
- **Theme**: Production-Ready Foundation â†’ Working Server
- **Journey Phase**: Deploy to Production (validates observability for production)
- **Estimated Effort**: Low
- **Priority**: 8 (Medium Cost of Delay - important for production but not blocking initial development)
